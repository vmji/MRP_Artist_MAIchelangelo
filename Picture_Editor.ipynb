{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42757381",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d225844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/point/veith/.venv/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "2025-07-16 11:39:20.596503: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-16 11:39:20.617803: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-16 11:39:20.624409: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-16 11:39:20.640172: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-16 11:39:21.810651: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc #GPU Memory Optimierung\n",
    "from diffusers import FluxPipeline, AutoPipelineForText2Image, StableDiffusion3Pipeline, FluxKontextPipeline\n",
    "from diffusers.utils import load_image\n",
    "# from accelerate import load_checkpoint_and_dispatch #manuelles verschieben Elemente auf GPU Geräte\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import datetime #benötigt zur Generierung von Suffixen für Speichern von Dateien\n",
    "import random\n",
    "import time\n",
    "from diffusers import BitsAndBytesConfig, PipelineQuantizationConfig, SD3Transformer2DModel # Quantisierungsoption\n",
    "\n",
    "# diffusers=0.33.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30d10b6",
   "metadata": {},
   "source": [
    "# Bildgenerierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72de3823",
   "metadata": {},
   "source": [
    "## Initialisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b283781",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_question = 0\n",
    "\n",
    "if model_question == 0:\n",
    "    model_path = \"/mount/point/models/FLUX.1-schnell\"\n",
    "    model = FluxPipeline.from_pretrained(model_path,\n",
    "                                        torch_dtype=torch.bfloat16, #torch.bfloat32\n",
    "                                        device_map = \"balanced\",\n",
    "                                        # max_memory={0: \"16GB\", 1: \"16GB\", 2: \"16GB\", 3: \"16GB\"} #max memory falls benötigt und andere GPUs in Nutzung\n",
    "                                        # text_encoder_2 = text_encoder\n",
    "                                        )\n",
    "\n",
    "else:\n",
    "    model_path = \"/mount/point/models/stable-diffusion-3.5-medium\"\n",
    "    model = StableDiffusion3Pipeline.from_pretrained(model_path,\n",
    "                                        torch_dtype=torch.bfloat16, #torch.bfloat32\n",
    "                                        device_map = \"balanced\",\n",
    "                                        #transformer=model_nf4, # Quantisierung des Transformer-Modells\n",
    "                                        )\n",
    "\n",
    "print(f\"Initialized image generating model: {model_path.rsplit('/')[-1]}\")\n",
    "\n",
    "#Bildgenerierungsfunktion\n",
    "def pic_gen(prompt, save_path = None, height = 1024, width = 1024,\n",
    "            guidance_scale = 0.0, num_inference_steps=4, generator_device = \"cpu\", seed = None,\n",
    "            image_num = 1, display_picture = True, return_dict=False):\n",
    " \n",
    "    \"\"\"Generate a picture according to your specifications\"\"\"\n",
    " \n",
    "    # Check if generator device is a valid device\n",
    "    assert generator_device in [\"cpu\", \"cuda\", \"ipu\", \"xpu\", \"mkldnn\", \"opengl\", \"opencl\", \"ideep\", \"hip\", \"ve\", \"fpga\", \"ort\", \"xla\", \"lazy\", \"vulkan\", \"mps\", \"meta\", \"hpu\", \"mtia\", \"privateuseone\"], \"Please enter a valid generator like the following: cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone\"\n",
    "   \n",
    "    if save_path != None:\n",
    "        assert isinstance(save_path, str), \"Please enter a valid string for the saving path of your image\"\n",
    " \n",
    "        path_test = save_path.rsplit(\"/\", maxsplit=1)[0] #split the path by the last separator\n",
    "        assert os.path.exists(path_test), \"Please enter a valid path\"\n",
    " \n",
    "        file_format = save_path.rsplit(\".\", maxsplit=1)[-1] #the file format as string\n",
    "        assert file_format in [\"png\", \"jpg\", \"jpeg\"], \"Please enter a valid picture format to save the image\"\n",
    "    \n",
    "    if seed != None:\n",
    "        generator = torch.Generator(generator_device).manual_seed(seed)\n",
    "    else:\n",
    "        generator = torch.Generator(generator_device)\n",
    "\n",
    "    image = model(\n",
    "        prompt,\n",
    "        height = height,\n",
    "        width = width,\n",
    "        num_images_per_prompt= image_num,\n",
    "        guidance_scale=guidance_scale,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        max_sequence_length=256, # if model_question == 1 else 512,\n",
    "        generator=generator, #alternativ zu \"cpu\" \"cuda\" verwenden\n",
    "        return_dict=return_dict,\n",
    "        )\n",
    "   \n",
    "    if save_path != None:\n",
    " \n",
    "        if image_num > 1: #saving all generated pictures\n",
    "            for i, pic in enumerate(image[0]):\n",
    "                img_path = save_path.rsplit(\".\", maxsplit=1)[0]\n",
    "                img_path = f\"{img_path}_{i}.{file_format}\"\n",
    "                pic.save(img_path)\n",
    "\n",
    "                if display_picture == True:\n",
    "                    im = Image.open(img_path)\n",
    "                    #im.show()\n",
    "                    display(im)\n",
    "       \n",
    "        else:\n",
    "            img_path = save_path.rsplit(\".\", maxsplit=1)[0]\n",
    "            img_path = f\"{img_path}.{file_format}\"\n",
    "            image[0][0].save(img_path)\n",
    "\n",
    "            if display_picture == True:\n",
    "                im = Image.open(img_path)\n",
    "                #im.show()\n",
    "                display(im)\n",
    "   \n",
    "    # Clean Up\n",
    "    gc.collect() #Free up GPU Memory\n",
    "    torch.cuda.empty_cache()\n",
    "   \n",
    "    return image #return all the generated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c008a",
   "metadata": {},
   "source": [
    "## Ausführung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4298d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "height = 1072\n",
    "width = 1920\n",
    "guidance_scale=3.5\n",
    "file_suffix = datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\") #generieren des aktuellen Suffixes\n",
    "save_path=f\"/mount/point/veith/generated_pictures/image_{file_suffix}.png\" # Speicherort für generierte Bilder #abspeichern als zufällige Zeichenfolgen\n",
    "image_num = 1\n",
    "num_inference_steps=10\n",
    "seed = None\n",
    "\n",
    "prompt = \"\"\"pareidolic anamorphosis of a hole in a brick wall morphed into a hublot of a sail boat, a window to the sea.\"\"\"\n",
    "\n",
    "image = pic_gen(prompt, \n",
    "        height = height,\n",
    "        width = width,\n",
    "        guidance_scale=guidance_scale,\n",
    "        save_path=save_path,\n",
    "        image_num = image_num,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        seed = seed, #423\n",
    "        display_picture=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3fab68",
   "metadata": {},
   "source": [
    "# Bildbearbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598f2329",
   "metadata": {},
   "source": [
    "## Initialisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74186b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b6b2ea0aed452493e1017af9e698d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fee6fa78dd442186529de6331fdab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5763ebf0f7084a6490c299b0861edbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"/mount/point/models/FLUX.1-Kontext-dev\"\n",
    "\n",
    "# 8-bit quantization für bottleneck transformer\n",
    "quantization_config = PipelineQuantizationConfig(\n",
    "    quant_backend=\"bitsandbytes_8bit\",\n",
    "    quant_kwargs={\n",
    "        \"load_in_8bit\": True,\n",
    "        \"llm_int8_threshold\": 6.0,\n",
    "        \"llm_int8_has_fp16_weight\": False,\n",
    "    },\n",
    "    components_to_quantize=[\"transformer\"]  # Only quantize the transformer component\n",
    ")\n",
    "\n",
    "model_edit = FluxKontextPipeline.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=quantization_config,  # Try 8-bit first\n",
    "    device_map=\"balanced\",\n",
    ")\n",
    "\n",
    "# Bildeditierungsfunktion\n",
    "\n",
    "def pic_edit(input_image, prompt: str, save_path: str = None,\n",
    "            guidance_scale = 0.0, num_inference_steps=8, generator_device = \"cpu\", seed = None,\n",
    "            image_num = 1, display_picture = True):\n",
    " \n",
    "    \"\"\"Generate a picture according to your specifications\"\"\"\n",
    " \n",
    "    # Check if generator device is a valid device\n",
    "    assert generator_device in [\"cpu\", \"cuda\", \"ipu\", \"xpu\", \"mkldnn\", \"opengl\", \"opencl\", \"ideep\", \"hip\", \"ve\", \"fpga\", \"ort\", \"xla\", \"lazy\", \"vulkan\", \"mps\", \"meta\", \"hpu\", \"mtia\", \"privateuseone\"], \"Please enter a valid generator like the following: cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone\"\n",
    "    \n",
    "    if save_path != None:\n",
    "        assert isinstance(save_path, str), \"Please enter a valid string for the saving path of your image\"\n",
    " \n",
    "        path_test = save_path.rsplit(\"/\", maxsplit=1)[0] #split the path by the last separator\n",
    "        assert os.path.exists(path_test), \"Please enter a valid path\"\n",
    " \n",
    "        file_format = save_path.rsplit(\".\", maxsplit=1)[-1] #the file format as string\n",
    "        assert file_format in [\"png\", \"jpg\", \"jpeg\"], \"Please enter a valid picture format to save the image\"\n",
    "    \n",
    "    if seed != None:\n",
    "        generator = torch.Generator(generator_device).manual_seed(seed)\n",
    "    else:\n",
    "        generator = torch.Generator(generator_device)\n",
    "    \n",
    "    image = model_edit(\n",
    "        image=input_image,\n",
    "        prompt=prompt,\n",
    "        height = input_image.size[1],\n",
    "        width = input_image.size[0],\n",
    "        max_area=input_image.size[0] * input_image.size[1],\n",
    "        num_images_per_prompt= image_num,\n",
    "        guidance_scale=guidance_scale,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        max_sequence_length=256, # if model_question == 1 else 512,\n",
    "        generator=generator, #alternativ zu \"cpu\" \"cuda\" verwenden\n",
    "        _auto_resize = False,\n",
    "        )\n",
    "    \n",
    "    if save_path != None:\n",
    " \n",
    "        if image_num > 1: #saving all generated pictures\n",
    "            for i, pic in enumerate(image[0]):\n",
    "                img_path = save_path.rsplit(\".\", maxsplit=1)[0]\n",
    "                img_path = f\"{img_path}_{i}.{file_format}\"\n",
    "                pic.save(img_path)\n",
    "\n",
    "                if display_picture == True:\n",
    "                    im = Image.open(img_path)\n",
    "                    #im.show()\n",
    "                    display(im)\n",
    "       \n",
    "        else:\n",
    "            img_path = save_path.rsplit(\".\", maxsplit=1)[0]\n",
    "            img_path = f\"{img_path}.{file_format}\"\n",
    "            image[0][0].save(img_path)\n",
    "\n",
    "            if display_picture == True:\n",
    "                im = Image.open(img_path)\n",
    "                #im.show()\n",
    "                display(im)\n",
    "   \n",
    "    # Clean Up\n",
    "    gc.collect() #Free up GPU Memory\n",
    "    torch.cuda.empty_cache()\n",
    "   \n",
    "    return image #return all the generated data\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aa601d",
   "metadata": {},
   "source": [
    "## Iterative Bearbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19340a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if i == 0:\n",
    "    input_image_path = \"/mount/point/veith/generated_pictures/image_250517_115934_1.png\" # Pfad des zu bearbeitenden Bildes\n",
    "    file_suffix = datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\") #generieren des aktuellen Suffixes\n",
    "    save_path = f\"/mount/point/veith/generated_pictures/edited_image_{file_suffix}.png\"\n",
    "else:\n",
    "    input_image_path = save_path # Weil bereits ein Bild generiert werden musste und i!=0 sein wird, wird der Speicherpfad zum Referenzpfad\n",
    "    # Speicherpfad bleibt konstant, weil dieser nur beim initialen Durchlauf generiert wird\n",
    "\n",
    "input_image = load_image(input_image_path)\n",
    "prompt = \"Add googly eyes\" # gewünschte Änderung des Bildes # Sollte zwischen Iterationen angepasst werden\n",
    "\n",
    "# Bildbearbeitungsparameter\n",
    "num_inference_steps = 16\n",
    "generator_device = \"cpu\"\n",
    "seed = None # Ersetzen mit int, falls spezifischer Seed gewünscht ist\n",
    "\n",
    "\n",
    "# Ausführen der Bildbearbeitung\n",
    "image = pic_edit(\n",
    "    input_image=input_image,\n",
    "    prompt=prompt,\n",
    "    guidance_scale=7.5,\n",
    "    save_path=save_path,\n",
    "    image_num=1,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    seed=seed,\n",
    "    display_picture=True,\n",
    ")\n",
    "i += 1 # Hochzählen, zum Signalisieren, dass ein Bild generiert wurde, welches fortfolgend stetig überschrieben wird"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
